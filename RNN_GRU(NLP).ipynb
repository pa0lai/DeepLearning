{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMabPCrmKJ/WB1HJQC4z9oi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pa0lai/deeplearning/blob/main/RNN_GRU(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 斷詞"
      ],
      "metadata": {
        "id": "9LrckpwjgdH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 英文斷詞"
      ],
      "metadata": {
        "id": "_oWzhgzfgdGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aB5YRRtgT0F"
      },
      "outputs": [],
      "source": [
        "# 英文斷詞\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(\"英文斷詞：\", text_to_word_sequence(\"I love jogging, and you?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 中文斷詞"
      ],
      "metadata": {
        "id": "8Z-qbdzggoXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install jieba（結巴）\n",
        "!pip install jieba\n",
        "\n",
        "# Get the Tokenization Dictionary for Traditional Chinese\n",
        "import os\n",
        "Dictionary_File = 'dict.txt.big'\n",
        "\n",
        "if not os.path.isfile(Dictionary_File):\n",
        "    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + Dictionary_File)\n",
        "\n",
        "# Get the Stop Words File for Traditional Chinese\n",
        "StopWords_File = \"stopWords_big5.txt\"\n",
        "\n",
        "if not os.path.isfile(StopWords_File):\n",
        "    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + StopWords_File)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nEs1BMCgm6i",
        "outputId": "568e782d-5df6-45e8-add1-978546306978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "\n",
        "# Set Dictionary for Traditional Chinese\n",
        "# jieba.set_dictionary(Dictionary_File)\n",
        "\n",
        "# Tokenization\n",
        "result = list(jieba.cut(\"我喜歡跑步，你呢？\"))\n",
        "print(\"中文斷詞（有標點）：\", result)\n",
        "\n",
        "# Remove Stop Words from Set\n",
        "stopWords = set(\"$!&#%\\()+-*/_,. 　?:;'\\\"<=>^`|~[]{}’0123456789?_“”、。《》！，：；？「」（）\")\n",
        "print(\"中文斷詞（無標點）：\", [word for word in result if word not in stopWords])\n",
        "\n",
        "# Remove Stop Words from Files\n",
        "stopWords = set()\n",
        "with open(StopWords_File, \"rt\", encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "    line = line.strip() # Remove trailing \\n\n",
        "    stopWords.add(line)\n",
        "print(\"中文斷詞（更精簡）：\", [word for word in result if word not in stopWords])"
      ],
      "metadata": {
        "id": "ZXB3P2U5gu6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文字數位化"
      ],
      "metadata": {
        "id": "TMELwDMhq4RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tokenizer object\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tk = Tokenizer(\n",
        "        num_words=None,\n",
        "        filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
        "        lower=True,\n",
        "        split=' ',\n",
        "        char_level=False,\n",
        "        oov_token='NiD'\n",
        "    )"
      ],
      "metadata": {
        "id": "_aBgvN0sq5zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Mapping by Corpus\n",
        "corpus = [\"I love jogging, and you?\",\n",
        "      \"I love reading!\"]\n",
        "tk.fit_on_texts(corpus)\n",
        "\n",
        "# Show the Mapping Table\n",
        "print(tk.word_index)    # WORD vs. NUMBER\n",
        "print(tk.index_word)    # NUMBER vs. WORD"
      ],
      "metadata": {
        "id": "vawzvfBuq8BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for Mapping Text into Sequence\n",
        "input_text = [\"I love jogging!\",\n",
        "        \"and I love reading, too!\"]\n",
        "\n",
        "seq = tk.texts_to_sequences(input_text)\n",
        "print(seq)\n",
        "\n",
        "# Test for Mapping Sequence into Text\n",
        "text = tk.sequences_to_texts(seq)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "qMwqwjvZq9hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 序列對齊（Sequence Alignment）"
      ],
      "metadata": {
        "id": "hKyw2OJJq_tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequence Padding Object\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_seq = pad_sequences(\n",
        "        sequences=seq,\n",
        "        maxlen=5,\n",
        "        dtype=\"int32\",\n",
        "        padding=\"pre\",\n",
        "        truncating=\"post\",\n",
        "        value=0\n",
        "    )\n",
        "\n",
        "print(padded_seq)"
      ],
      "metadata": {
        "id": "vWGZysderBIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wG42mpySyaAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 編碼（Encoding）"
      ],
      "metadata": {
        "id": "QUlZMrkGyZzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"獨熱編碼 -------------\")\n",
        "print(to_categorical(padded_seq))"
      ],
      "metadata": {
        "id": "oVLjXNSPybvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Hot Encoding\n",
        "print(\"多熱編碼 -------------\")\n",
        "print(tk.texts_to_matrix(input_text))"
      ],
      "metadata": {
        "id": "V3zJkV05ydUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embedding\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "emb = layers.Embedding(8, 3)\n",
        "\n",
        "# tf.constant(): Convert immediate values into tensor\n",
        "result = emb(tf.constant(padded_seq))\n",
        "print(\"詞向量嵌入 -------------\")\n",
        "print(result.numpy())"
      ],
      "metadata": {
        "id": "AvmMGkwLye68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}